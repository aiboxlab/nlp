{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos\n",
    "\n",
    "Experimentos são a principal forma de agrupar 3 entidades:\n",
    "\n",
    "1. **Datasets**: conjunto de textos acompanhados de um *target*, representando um problema de classificação ou regressão;\n",
    "2. **Pipelines**: são capazes de receber um ou mais textos como entrada e produzir uma saída para o problema de classificação/regressão;\n",
    "3. **Métricas**: permitem avaliar o desempenho de uma ou mais pipelines para o problema em questão;\n",
    "\n",
    "A biblioteca `aibox-nlp` disponibiliza diferentes métodos para construção e execução de experimentos em seu pacote `aibox.nlp.experiments`. É possível construir um experimento instanciando cada um dos componentes individualmente ou através do pacote `aibox.nlp.factory`, que possui facilidades para obter as diversas classes da biblioteca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from aibox.nlp import serialization\n",
    "from aibox.nlp.factory.experiment import SimpleExperimentBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 1 - Construindo um Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Construindo um experimento para classificação no Essay-BR estendido ===\n",
    "# Por simplicidade, vamos instanciar um experimento\n",
    "#   para comparar algumas abordagens para classificação\n",
    "#   da competência 1 do dataset Essay-BR.\n",
    "builder = SimpleExperimentBuilder()\n",
    "\n",
    "# Inicialmente, vamos definir o dataset\n",
    "builder.dataset('essayBR',\n",
    "                extended=True,\n",
    "                target_competence='C1')\n",
    "\n",
    "# Também é possível passar uma instância\n",
    "#   de um Dataset diretamente:\n",
    "# builder.custom_dataset(ds)\n",
    "\n",
    "# Vamos definir o tipo do problema\n",
    "builder.classification()\n",
    "\n",
    "# Vamos definir a seed randômica\n",
    "builder.seed(42)\n",
    "\n",
    "# Depois, vamos definir algumas métricas\n",
    "#   que devem ser calculadas\n",
    "builder.add_metric('precision', average='weighted')\n",
    "builder.add_metric('recall', average='weighted')\n",
    "builder.add_metric('f1', average='weighted')\n",
    "builder.add_metric('kappa')\n",
    "builder.add_metric('neighborKappa')\n",
    "\n",
    "# Depois, vamos definir qual a métrica\n",
    "#   que deve ser utilizar para escolher a\n",
    "#   melhor pipeline\n",
    "builder.best_criteria('precision', average='weighted')\n",
    "\n",
    "# Agora, vamos adicionar algumas pipelines baseadas\n",
    "#   em extração de característica\n",
    "builder.add_feature_pipeline(\n",
    "    features=['readabilityBR',\n",
    "              'regencyBR',\n",
    "              'syntacticComplexityBR',\n",
    "              'textualSimplicityBR'],\n",
    "    estimators=['svm',\n",
    "                'etreesClf',\n",
    "                'lgbmClf',\n",
    "                'xgbClf'],\n",
    "    names=['svm+features',\n",
    "           'etrees+features',\n",
    "           'lgbm+features',\n",
    "           'xgb+features'])\n",
    "\n",
    "# Agora, vamos adicionar algumas pipelines baseadas\n",
    "#   em outras estratégias de vetorização\n",
    "builder.add_vectorizer_pipeline('tfidfVectorizer',\n",
    "                                estimators=['etreesClf',\n",
    "                                            'lgbmClf',\n",
    "                                            'xgbClf'],\n",
    "                                names=['etrees+tfidf',\n",
    "                                       'lgbm+tfidf',\n",
    "                                       'xgb+tfidf'],\n",
    "                                estimators_configs=[dict(n_estimators=20),\n",
    "                                                    dict(n_estimators=20),\n",
    "                                                    dict(n_estimators=20)])\n",
    "builder.add_vectorizer_pipeline('bertVectorizer',\n",
    "                                estimators=['svm',\n",
    "                                            'etreesClf',\n",
    "                                            'lgbmClf',\n",
    "                                            'xgbClf'],\n",
    "                                names=['svm+bert',\n",
    "                                       'etrees+bert',\n",
    "                                       'lgbm+bert',\n",
    "                                       'xgb+bert'])\n",
    "\n",
    "# Vamos aproveitar um conjunto de características\n",
    "#   pré-extraídos se ele existir:\n",
    "features = None\n",
    "try:\n",
    "    features = pd.read_csv('essay_br_extended_features.csv')\n",
    "except Exception:\n",
    "    ...\n",
    "\n",
    "# Uma vez que tenhamos configurado o experimento,\n",
    "#   podemos obter uma instância:\n",
    "experiment = builder.build(features_df=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Setting up experiment...\n",
      "[INFO] [aibox.nlp.experiments.simple_experiment] Obtaining train and test split...\n",
      "[INFO] [aibox.nlp.experiments.simple_experiment] Train has 5251 samples, Test has 1313 samples.\n",
      "[INFO] [aibox.nlp.experiments.simple_experiment] Run started.\n",
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"xgb+features\" (1/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b125b4dbb214fa298337ef016b92df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21c9cb5a0ae4464a5f42549dd1a7d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"lgbm+features\" (2/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a20984da7f4ddc859ee8d0fa494816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca18b7c090b042c89da2c9ece49f5cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"etrees+features\" (3/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d080cf21de42a381cd2e1240202316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc577415cd445fcacb582fb8e7e6cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"svm+features\" (4/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bc8553801449acb4a635d7a8c6c999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79288fefd0d248ada2f9daf5200a997b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"xgb+bert\" (5/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d7ecc08d5c464087017ffc7df8f913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1964062461914d74971df1a9e1b1e79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"lgbm+bert\" (6/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97df4125fd4f445987447fc26d0d55be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb2f19434c84be49c4d15822a74738d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"etrees+bert\" (7/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4e42b8ee0b4d70a2dfa78cf19c4a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2aa4a3c9b94c628472892522170199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"svm+bert\" (8/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75db419538b427aae2afdb89a064bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00b3bbfae5b4f6eb1b86a04c7b27029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"xgb+tfidf\" (9/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d0f4fe2eaf0410bb36d09da070261d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414a0de1a5d346498ec42f9290892475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"lgbm+tfidf\" (10/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d009a1b08e492da82dc06bb9168667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1179c5c19e410f92e7c9949013f873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Started pipeline \"etrees+tfidf\" (11/11)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ef3035b22c48d58f8bbac182e40bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/5251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76644f5be76442c2a2e277e6ca473713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [aibox.nlp.experiments.simple_experiment] Run finished in 539.52 seconds.\n",
      "Best pipeline: etrees+bert\n"
     ]
    }
   ],
   "source": [
    "# === Executando o experimento ===\n",
    "result = experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'etrees+bert'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Inspecionando os resultados ===\n",
    "# Podemos obter o nome da melhor pipeline:\n",
    "result.best_pipeline.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Weighted Precision\": 0.6915916204452515,\n",
      "  \"Weighted Recall\": 0.6755521893501282,\n",
      "  \"Weighted F1-score\": 0.6246420741081238,\n",
      "  \"Kappa\": 0.4168861210346222,\n",
      "  \"Neighbor Kappa\": 0.4168861210346222\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Também podemos listar o valor das melhores métricas:\n",
    "print(json.dumps({k: v.tolist() for k, v in result.best_metrics.items()},\n",
    "                 indent=2,\n",
    "                 ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"xgb+features\": {\n",
      "    \"Weighted Precision\": 0.4880306124687195,\n",
      "    \"Weighted Recall\": 0.5300837755203247,\n",
      "    \"Weighted F1-score\": 0.49591535329818726,\n",
      "    \"Kappa\": 0.1701161414384842,\n",
      "    \"Neighbor Kappa\": 0.1701161414384842\n",
      "  },\n",
      "  \"lgbm+features\": {\n",
      "    \"Weighted Precision\": 0.4873538613319397,\n",
      "    \"Weighted Recall\": 0.5277989506721497,\n",
      "    \"Weighted F1-score\": 0.4935830533504486,\n",
      "    \"Kappa\": 0.1650332659482956,\n",
      "    \"Neighbor Kappa\": 0.1650332659482956\n",
      "  },\n",
      "  \"etrees+features\": {\n",
      "    \"Weighted Precision\": 0.46003034710884094,\n",
      "    \"Weighted Recall\": 0.5354150533676147,\n",
      "    \"Weighted F1-score\": 0.48790010809898376,\n",
      "    \"Kappa\": 0.16338065266609192,\n",
      "    \"Neighbor Kappa\": 0.16338065266609192\n",
      "  },\n",
      "  \"svm+features\": {\n",
      "    \"Weighted Precision\": 0.22876513004302979,\n",
      "    \"Weighted Recall\": 0.4782939851284027,\n",
      "    \"Weighted F1-score\": 0.3094988465309143,\n",
      "    \"Kappa\": 0.0,\n",
      "    \"Neighbor Kappa\": 0.0\n",
      "  },\n",
      "  \"xgb+bert\": {\n",
      "    \"Weighted Precision\": 0.6563370823860168,\n",
      "    \"Weighted Recall\": 0.6839299201965332,\n",
      "    \"Weighted F1-score\": 0.6455287933349609,\n",
      "    \"Kappa\": 0.44415372610092163,\n",
      "    \"Neighbor Kappa\": 0.44415372610092163\n",
      "  },\n",
      "  \"lgbm+bert\": {\n",
      "    \"Weighted Precision\": 0.660933792591095,\n",
      "    \"Weighted Recall\": 0.6884996294975281,\n",
      "    \"Weighted F1-score\": 0.6516293883323669,\n",
      "    \"Kappa\": 0.45318907499313354,\n",
      "    \"Neighbor Kappa\": 0.45318907499313354\n",
      "  },\n",
      "  \"etrees+bert\": {\n",
      "    \"Weighted Precision\": 0.6915916204452515,\n",
      "    \"Weighted Recall\": 0.6755521893501282,\n",
      "    \"Weighted F1-score\": 0.6246420741081238,\n",
      "    \"Kappa\": 0.4168861210346222,\n",
      "    \"Neighbor Kappa\": 0.4168861210346222\n",
      "  },\n",
      "  \"svm+bert\": {\n",
      "    \"Weighted Precision\": 0.589119017124176,\n",
      "    \"Weighted Recall\": 0.6808834671974182,\n",
      "    \"Weighted F1-score\": 0.6263136267662048,\n",
      "    \"Kappa\": 0.4271623194217682,\n",
      "    \"Neighbor Kappa\": 0.4271623194217682\n",
      "  },\n",
      "  \"xgb+tfidf\": {\n",
      "    \"Weighted Precision\": 0.6013146638870239,\n",
      "    \"Weighted Recall\": 0.6443259716033936,\n",
      "    \"Weighted F1-score\": 0.5968663096427917,\n",
      "    \"Kappa\": 0.3617754876613617,\n",
      "    \"Neighbor Kappa\": 0.3617754876613617\n",
      "  },\n",
      "  \"lgbm+tfidf\": {\n",
      "    \"Weighted Precision\": 0.6582549214363098,\n",
      "    \"Weighted Recall\": 0.6549885869026184,\n",
      "    \"Weighted F1-score\": 0.6103717088699341,\n",
      "    \"Kappa\": 0.38397666811943054,\n",
      "    \"Neighbor Kappa\": 0.38397666811943054\n",
      "  },\n",
      "  \"etrees+tfidf\": {\n",
      "    \"Weighted Precision\": 0.628661036491394,\n",
      "    \"Weighted Recall\": 0.6252856254577637,\n",
      "    \"Weighted F1-score\": 0.5745158195495605,\n",
      "    \"Kappa\": 0.3242253065109253,\n",
      "    \"Neighbor Kappa\": 0.3242253065109253\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Também podemos listar o valor de todas as métricas calculadas:\n",
    "print(json.dumps({k: {k_: v_.tolist() for k_, v_ in v.items()} \n",
    "                  for k, v in result.metrics_history.items()},\n",
    "                 indent=2,\n",
    "                 ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>adapted_dalechall</th>\n",
       "      <th>adverbs_before_main_verb_ratio</th>\n",
       "      <th>brunet_indice</th>\n",
       "      <th>clauses_per_sentence</th>\n",
       "      <th>coord_conj_ratio</th>\n",
       "      <th>coordinate_conjunctions_per_clauses</th>\n",
       "      <th>dialog_pron_ratio</th>\n",
       "      <th>easy_conj_ratio</th>\n",
       "      <th>flesch_indice</th>\n",
       "      <th>...</th>\n",
       "      <th>sentences_with_5_clauses</th>\n",
       "      <th>sentences_with_6_clauses</th>\n",
       "      <th>sentences_with_7_clauses</th>\n",
       "      <th>short_sentence_ratio</th>\n",
       "      <th>simple_word_ratio</th>\n",
       "      <th>std_noun_phrase</th>\n",
       "      <th>subord_conj_ratio</th>\n",
       "      <th>token_var_idx</th>\n",
       "      <th>verb_regency_score</th>\n",
       "      <th>words_before_main_verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quando falamos em cultura cultura, logo pensam...</td>\n",
       "      <td>6.075747</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.485317</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.241803</td>\n",
       "      <td>32.183328</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.809721</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>55.058231</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Em uma época na qual vivemos hoje, onde o maio...</td>\n",
       "      <td>5.751029</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.908926</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>39.019286</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.769217</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>76.765148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Atualmente a ciência já desmitificou vários fa...</td>\n",
       "      <td>6.830699</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>10.952084</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>-10.617132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.385570</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>70.417395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  adapted_dalechall  \\\n",
       "0  Quando falamos em cultura cultura, logo pensam...           6.075747   \n",
       "1  Em uma época na qual vivemos hoje, onde o maio...           5.751029   \n",
       "2  Atualmente a ciência já desmitificou vários fa...           6.830699   \n",
       "\n",
       "   adverbs_before_main_verb_ratio  brunet_indice  clauses_per_sentence  \\\n",
       "0                        1.000000      11.485317                   4.8   \n",
       "1                        0.333333       9.908926                   6.0   \n",
       "2                        1.200000      10.952084                   5.0   \n",
       "\n",
       "   coord_conj_ratio  coordinate_conjunctions_per_clauses  dialog_pron_ratio  \\\n",
       "0          0.545455                             0.500000           0.083333   \n",
       "1          0.454545                             0.277778           0.000000   \n",
       "2          0.500000                             0.450000           0.000000   \n",
       "\n",
       "   easy_conj_ratio  flesch_indice  ...  sentences_with_5_clauses  \\\n",
       "0         0.241803      32.183328  ...                         0   \n",
       "1         0.190476      39.019286  ...                         0   \n",
       "2         0.266667     -10.617132  ...                         0   \n",
       "\n",
       "   sentences_with_6_clauses  sentences_with_7_clauses  short_sentence_ratio  \\\n",
       "0                         1                         1                   0.0   \n",
       "1                         0                         1                   0.0   \n",
       "2                         0                         2                   0.0   \n",
       "\n",
       "   simple_word_ratio  std_noun_phrase  subord_conj_ratio  token_var_idx  \\\n",
       "0                0.0         0.809721           0.454545      55.058231   \n",
       "1                0.0         0.769217           0.545455      76.765148   \n",
       "2                0.0         1.385570           0.500000      70.417395   \n",
       "\n",
       "   verb_regency_score  words_before_main_verb  \n",
       "0            0.833333                      12  \n",
       "1            1.000000                      18  \n",
       "2            1.000000                       4  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Por último, também é possível recuperar um DataFrame com as características\n",
    "#   extraídas para os textos do dataset.\n",
    "result.extras.df_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos salvar a extração de características \n",
    "#   para reutiliza rem outro momento.\n",
    "from pathlib import Path\n",
    "\n",
    "output = Path('essay_br_extended_features.csv')\n",
    "\n",
    "if not output.exists():\n",
    "    result.extras.df_features.to_csv(output,\n",
    "                                     index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também podemos realizar a serialização\n",
    "#   da melhor pipeline\n",
    "pipeline = result.best_pipeline\n",
    "serialization.save_pipeline(pipeline, f'{pipeline.name}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc5d530ed82423480869baa9627b5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Vetorização:   0%|          | 0/1313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Depois, podemos recuperar essa pipeline\n",
    "#   e utilizá-la para novas predições\n",
    "pipeline = serialization.load_pipeline(f'{pipeline.name}.joblib')\n",
    "predictions = pipeline.predict(result.test_df.text.to_numpy())\n",
    "assert (predictions == result.best_pipeline_test_predictions).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 2 - Utilizando Experimentos Pré-Inicializados\n",
    "\n",
    "O pacote `aibox.nlp.factory` também oferece experimentos pré-inicializados para serem utilizados como baselines. Essencialmente, são utilizadas as configurações padrão para todos os estimadores, vetorizados e extratores de característica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Construindo um experimento para classificação no Essay-BR clássico ===\n",
    "\n",
    "# Inicializando um experimento baseado em características com o uso\n",
    "#   de estimadores clássicos (SVM, Random Forest, XGBoost, etc) e\n",
    "#   métricas padrão para o problema (precision, recall, f1-score, kappa ou \n",
    "#   RMSE, MAE, R2 e MSE)\n",
    "builder = SimpleExperimentBuilder.features_experiment(42, 'classification')\n",
    "\n",
    "# Depois, só precisamos definir o dataset\n",
    "builder.dataset('essayBR',\n",
    "                extended=False,\n",
    "                target_competence='C1')\n",
    "\n",
    "# Vamos aproveitar um conjunto de características\n",
    "#   pré-extraídos se ele existir:\n",
    "features = None\n",
    "try:\n",
    "    features = pd.read_csv('essay_br_classic_features.csv')\n",
    "except Exception:\n",
    "    ...\n",
    "\n",
    "# Uma vez que tenhamos configurado o experimento,\n",
    "#   podemos obter uma instância:\n",
    "experiment = builder.build(features_df=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Executando o experimento ===\n",
    "# A extração de todas as características\n",
    "#   para o dataset pode demorar\n",
    "#   consideravelmente (2h+)\n",
    "result = experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inspecionando os resultados ===\n",
    "# Podemos obter o nome da melhor pipeline:\n",
    "print('Melhor pipeline:', result.best_pipeline.name)\n",
    "\n",
    "# Também podemos obter as métricas\n",
    "print(json.dumps({k: v.tolist() for k, v in result.best_metrics.items()},\n",
    "                 indent=2,\n",
    "                 ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos salvar a extração de características\n",
    "# para reutilizar em outro momento.\n",
    "from pathlib import Path\n",
    "\n",
    "output = Path('essay_br_classic_features.csv')\n",
    "\n",
    "if not output.exists():\n",
    "    result.extras.df_features.to_csv(output,\n",
    "                                     index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
