{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos\n",
    "\n",
    "Experimentos são a principal forma de agrupar 3 entidades:\n",
    "\n",
    "1. **Datasets**: conjunto de textos acompanhados de um *target*, representando um problema de classificação ou regressão;\n",
    "2. **Pipelines**: são capazes de receber um ou mais textos como entrada e produzir uma saída para o problema de classificação/regressão;\n",
    "3. **Métricas**: permitem avaliar o desempenho de uma ou mais pipelines para o problema em questão;\n",
    "\n",
    "A biblioteca `aibox-nlp` disponibiliza diferentes métodos para construção e execução de experimentos em seu pacote `aibox.nlp.experiments`. É possível construir um experimento instanciando cada um dos componentes individualmente ou através do pacote `aibox.nlp.factory`, que possui facilidades para obter as diversas classes da biblioteca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from aibox.nlp import serialization\n",
    "from aibox.nlp.factory.experiment import SimpleExperimentBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 1 - Construindo um Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Construindo um experimento para classificação no Essay-BR estendido ===\n",
    "# Por simplicidade, vamos instanciar um experimento\n",
    "#   para comparar algumas abordagens para classificação\n",
    "#   da competência 1 do dataset Essay-BR.\n",
    "builder = SimpleExperimentBuilder()\n",
    "\n",
    "# Inicialmente, vamos definir o dataset\n",
    "builder.dataset('essayBR',\n",
    "                extended=True,\n",
    "                target_competence='C1')\n",
    "\n",
    "# Também é possível passar uma instância\n",
    "#   de um Dataset diretamente:\n",
    "# builder.custom_dataset(ds)\n",
    "\n",
    "# Vamos definir o tipo do problema\n",
    "builder.classification()\n",
    "\n",
    "# Vamos definir a seed randômica\n",
    "builder.seed(42)\n",
    "\n",
    "# Depois, vamos definir algumas métricas\n",
    "#   que devem ser calculadas\n",
    "builder.add_metric('precision', average='weighted')\n",
    "builder.add_metric('recall', average='weighted')\n",
    "builder.add_metric('f1', average='weighted')\n",
    "builder.add_metric('kappa')\n",
    "builder.add_metric('neighborKappa')\n",
    "\n",
    "# Depois, vamos definir qual a métrica\n",
    "#   que deve ser utilizar para escolher a\n",
    "#   melhor pipeline\n",
    "builder.best_criteria('precision', average='weighted')\n",
    "\n",
    "# Agora, vamos adicionar algumas pipelines baseadas\n",
    "#   em extração de característica\n",
    "builder.add_feature_pipeline(\n",
    "    features=['readabilityBR',\n",
    "              'regencyBR',\n",
    "              'syntacticComplexityBR',\n",
    "              'textualSimplicityBR'],\n",
    "    estimators=['svm',\n",
    "                'etreesClf',\n",
    "                'lgbmClf',\n",
    "                'xgbClf'],\n",
    "    names=['svm+features',\n",
    "           'etrees+features',\n",
    "           'lgbm+features',\n",
    "           'xgb+features'])\n",
    "\n",
    "# Agora, vamos adicionar algumas pipelines baseadas\n",
    "#   em outras estratégias de vetorização\n",
    "builder.add_vectorizer_pipeline('tfidfVectorizer',\n",
    "                                estimators=['etreesClf',\n",
    "                                            'lgbmClf',\n",
    "                                            'xgbClf'],\n",
    "                                names=['etrees+tfidf',\n",
    "                                       'lgbm+tfidf',\n",
    "                                       'xgb+tfidf'],\n",
    "                                estimators_configs=[dict(n_estimators=20),\n",
    "                                                    dict(n_estimators=20),\n",
    "                                                    dict(n_estimators=20)])\n",
    "builder.add_vectorizer_pipeline('bertVectorizer',\n",
    "                                estimators=['svm',\n",
    "                                            'etreesClf',\n",
    "                                            'lgbmClf',\n",
    "                                            'xgbClf'],\n",
    "                                names=['svm+bert',\n",
    "                                       'etrees+bert',\n",
    "                                       'lgbm+bert',\n",
    "                                       'xgb+bert'])\n",
    "\n",
    "# Vamos aproveitar um conjunto de características\n",
    "#   pré-extraídos se ele existir:\n",
    "features = None\n",
    "try:\n",
    "    features = pd.read_csv('essay_br_extended_features.csv')\n",
    "except Exception:\n",
    "    ...\n",
    "\n",
    "# Uma vez que tenhamos configurado o experimento,\n",
    "#   podemos obter uma instância:\n",
    "experiment = builder.build(features_df=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Executando o experimento ===\n",
    "result = experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inspecionando os resultados ===\n",
    "# Podemos obter o nome da melhor pipeline:\n",
    "result.best_pipeline.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também podemos listar o valor das melhores métricas:\n",
    "print(json.dumps({k: v.tolist() for k, v in result.best_metrics.items()},\n",
    "                 indent=2,\n",
    "                 ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também podemos listar o valor de todas as métricas calculadas:\n",
    "print(json.dumps({k: {k_: v_.tolist() for k_, v_ in v.items()} \n",
    "                  for k, v in result.metrics_history.items()},\n",
    "                 indent=2,\n",
    "                 ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por último, também é possível recuperar um DataFrame com as características\n",
    "#   extraídas para os textos do dataset.\n",
    "result.extras.df_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos salvar a extração de características \n",
    "#   para reutiliza rem outro momento.\n",
    "from pathlib import Path\n",
    "\n",
    "output = Path('essay_br_extended_features.csv')\n",
    "\n",
    "if not output.exists():\n",
    "    result.extras.df_features.to_csv(output,\n",
    "                                     index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também podemos realizar a serialização\n",
    "#   da melhor pipeline\n",
    "pipeline = result.best_pipeline\n",
    "serialization.save_pipeline(pipeline, f'{pipeline.name}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depois, podemos recuperar essa pipeline\n",
    "#   e utilizá-la para novas predições\n",
    "pipeline = serialization.load_pipeline(f'{pipeline.name}.joblib')\n",
    "predictions = pipeline.predict(result.test_df.text.to_numpy())\n",
    "assert (predictions == result.best_pipeline_test_predictions).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 2 - Utilizando Experimentos Pré-Inicializados\n",
    "\n",
    "O pacote `aibox.nlp.factory` também oferece experimentos pré-inicializados para serem utilizados como baselines. Essencialmente, são utilizadas as configurações padrão para todos os estimadores, vetorizados e extratores de característica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Construindo um experimento para classificação no Essay-BR clássico ===\n",
    "\n",
    "# Inicializando um experimento baseado em características com o uso\n",
    "#   de estimadores clássicos (SVM, Random Forest, XGBoost, etc) e\n",
    "#   métricas padrão para o problema (precision, recall, f1-score, kappa ou \n",
    "#   RMSE, MAE, R2 e MSE)\n",
    "builder = SimpleExperimentBuilder.features_experiment(42, 'classification')\n",
    "\n",
    "# Depois, só precisamos definir o dataset\n",
    "builder.dataset('essayBR',\n",
    "                extended=False,\n",
    "                target_competence='C1')\n",
    "\n",
    "# Vamos aproveitar um conjunto de características\n",
    "#   pré-extraídos se ele existir:\n",
    "features = None\n",
    "try:\n",
    "    features = pd.read_csv('essay_br_classic_features.csv')\n",
    "except Exception:\n",
    "    ...\n",
    "\n",
    "# Uma vez que tenhamos configurado o experimento,\n",
    "#   podemos obter uma instância:\n",
    "experiment = builder.build(features_df=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Executando o experimento ===\n",
    "# A extração de todas as características\n",
    "#   para o dataset pode demorar\n",
    "#   consideravelmente (2h+)\n",
    "result = experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inspecionando os resultados ===\n",
    "# Podemos obter o nome da melhor pipeline:\n",
    "print('Melhor pipeline:', result.best_pipeline.name)\n",
    "\n",
    "# Também podemos obter as métricas\n",
    "print(json.dumps({k: v.tolist() for k, v in result.best_metrics.items()},\n",
    "                 indent=2,\n",
    "                 ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos salvar a extração de características\n",
    "# para reutilizar em outro momento.\n",
    "from pathlib import Path\n",
    "\n",
    "output = Path('essay_br_classic_features.csv')\n",
    "\n",
    "if not output.exists():\n",
    "    result.extras.df_features.to_csv(output,\n",
    "                                     index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
